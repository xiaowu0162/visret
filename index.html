<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Visualized T2I Retrieval</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="icon" href="./static/images/mathvista.png">

  <script type="text/javascript" src="static/js/sort-table.js" defer></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>

  <script src="./static/js/index.js"></script>
  
</head>
<body>

<!-- title and author -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
          <span class="mathvista" style="vertical-align: middle">Visualized Text-to-Image Retrieval</span>
          </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            
            <!-- <br> -->
            <!-- with GPT-4V, Bard, and Other Large Multimodal Models -->
          </h2>
          <!-- <h1 class="title is-1 publication-title">VIDEOPHY: Evaluating Physical Commonsense In Video Generation</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xiaowu0162.github.io/">Di Wu<span style="color: red;">*</span></a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com.my/citations?hl=en&user=hZPIICQAAAAJ">Yixin Wan<span style="color: red;">*</span></a>,</span>
            <span class="author-block">
              <a href="https://web.cs.ucla.edu/~kwchang/">Kai-Wei Chang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            (<span style="color: red;">*</span>, Equal Contribution)
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of California, Los Angeles</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/xiaowu0162/Visualize-then-Retrieve"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code and Data</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block"> -->
                <!-- <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- top 2 images -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-5 has-text-centered">
        We propose <span class="dnerf">Visualize-then-Retrieve (VisRet)</span>, a new paradigm for Text-to-Image (T2I) retrieval that mitigates the limitations of cross-modal similarity alignment of existing multi-modal embeddings. 
      </h2>
      <br>
      <h2 class="title is-3 has-text-centered">Methodology</h2>
      <div class="images-container" style="display: flex; justify-content: center; align-items: center; width: 100%; height: 300px;">
        <img src="./images/visret-main-figure.png" alt="Image 1" style="height: 110%; object-fit: contain;" >
      </div>
      <br>
      <h2 class="has-text-centered">
        <span class="dnerf">VisRet</span> first <b>projects</b> textual queries into the image modality via T2I generation. Then, it performs retrieval <b>within the image modality</b> to bypass the weaknesses of cross-modal retrievers in recognizing subtle visual-spatial features.
      </h2>
    </div>
  </div>
</section>


<!-- Benchmark -->
<section class="section">
  <div class="container" style="margin-top: -100px;">
    <div class="columns is-centered m-2">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3 has-text-centered">Visual-RAG-ME: A Challenging Benchmark</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="./images/demo-1.png" alt="benchmark_statistics" style="max-width:50%;"/>
              <!-- <p> 
                Key statistics of the <span class="mathvista" style="vertical-align: middle">VideoPhy</span> dataset.
              </p>  -->
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="./images/demo-2.png" alt="benchmark_statistics" style="max-width:50%;"/>
              <!-- <p> 
                Key statistics of the <span class="mathvista" style="vertical-align: middle">VideoPhy</span> dataset.
              </p>  -->
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="./images/demo-3.png" alt="benchmark_statistics" style="max-width:50%;"/>
              <!-- <p> 
                Key statistics of the <span class="mathvista" style="vertical-align: middle">VideoPhy</span> dataset.
              </p>  -->
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="./images/demo-4.png" alt="benchmark_statistics" style="max-width:50%;"/>
              <!-- <p> 
                Key statistics of the <span class="mathvista" style="vertical-align: middle">VideoPhy</span> dataset.
              </p>  -->
            </div>
          </div>
        </div>

      </div>
    </div>
</section>



<section class="section">
  <div class="container" style="margin-top: -100px;">
    <div class="columns is-centered m-2">
      <div class="column is-full  content">
        <h2 class="title is-3 has-text-centered"><span class="dnerf">VisRet</span> Improves Retrieval </h2>
        <!-- <div>
          <p>We use VIDEOCON, an open-source generative video-text language model with 7B parameters, that is trained on real videos for robust text adherence evaluation. Specifically, we prompt VIDEOCON to generate a response (Yes/No) to the text adherence and physical commonsense of the generated videos. </p>
        </div> -->
        <!-- <div style="text-align: center;">
          <img src="./images/formular.png" alt="formular" style="max-width:40%;"/>
        </div> -->
        
        <div class="has-text-centered">
          <!-- <h3 class="title is-4" style="margin-top: 60px">Effectiveness of Our Auto-Evaluator</h3> -->
          <img src="./images/visret-table-1.png" alt="roc-auc" style="max-width:50%;"/>
              <p>
                Evaluation results across three T2I retrieval benchmarks using different retrieval strategies and retrievers. We use <b>GPT-4o </b>for T2I instruction generation and <b>GPT-Image-1</b> for T2I generation. The best results in each column within each retriever group are boldfaced. R = Recall. N = NDCG.
              </p>
        </div>
      </div>
    </div>
</section>



<section class="section">
  <div class="container" style="margin-top: -100px;">
    <div class="columns is-centered m-2">
      <div class="column is-full  content">
        <h2 class="title is-3 has-text-centered"><span class="dnerf">VisRet</span> Improves Downstream VQA </h2>
        <!-- <div>
          <p>We use VIDEOCON, an open-source generative video-text language model with 7B parameters, that is trained on real videos for robust text adherence evaluation. Specifically, we prompt VIDEOCON to generate a response (Yes/No) to the text adherence and physical commonsense of the generated videos. </p>
        </div> -->
        <!-- <div style="text-align: center;">
          <img src="./images/formular.png" alt="formular" style="max-width:40%;"/>
        </div> -->
        
        <div class="has-text-centered">
          <!-- <h3 class="title is-4" style="margin-top: 60px">Effectiveness of Our Auto-Evaluator</h3> -->
          <img src="./images/visret-table-6.png" alt="roc-auc" style="max-width:50%;"/>
              <p>
                VQA performance comparison using different LVLMs as instruction generators for VisRet and query rephrase models. CLIP is used as the retriever. Boldfaced numbers indicate the best in each column.
              </p>
        </div>
      </div>
    </div>
</section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop" content> 
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{wu2024synchronous,
      title={Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation}, 
      author={Di Wu and Jia-Chen Gu and Fan Yin and Nanyun Peng and Kai-Wei Chang},
      year={2024},
      eprint={2406.13692},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}</code></pre>
</div>
  </section>
 

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
        href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
